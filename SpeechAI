[["AAAAAACUq78AAAAAAAA5wAAAAADAic2/AAAAAAAA8D8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAA8D8AAAAAAAAAQAAAAAAAAPA/W11pZmZm","Microphone"],["AAAAAACUq78AAAAAAIA6wAAAAADAic2/AAAAAAAA8D8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAA8D8AAAAAAADwPwAAAAAAAPA/Y19iZmZm","Port",{"PortID":"4"}],["AAAAAKBW8j8AAAAAAIA6wAAAAACQneg/AAAAAAAA8D8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAA8D8AAAAAAADwPwAAAAAAAPA/Y19iZmZm","Port",{"PortID":"3"}],["AAAAAFhqE8AAAAAAAEA7wAAAAAAgO9E/AAAAAAAA8L8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAAFEAAAAAAAADgPwAAAAAAAABA3NzdZmZm","Keyboard"],["AAAAAAC1wj8AAAAAAEA7wAAAAAAgO9E/AAAAAAAA8D8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAACEAAAAAAAADgPwAAAAAAAABALGUdZmZm","Microcontroller",{"Code":"ACTIVATION_RESPONSE = 1\n\n\n\n\nNeuralNetwork = {\n\n\ttransfer = function( x) return 1 / (1 + math.exp(-x / ACTIVATION_RESPONSE)) end --This is the Transfer function (in this case a sigmoid)\n\n}\n\n\n\nfunction NeuralNetwork.create( _numInputs, _numOutputs, _numHiddenLayers, _neuronsPerLayer, _learningRate)\n\n\t_numInputs = _numInputs or 1\n\n\t_numOutputs = _numOutputs or 1\n\n\t_numHiddenLayers = _numHiddenLayers or math.ceil(_numInputs/2)\n\n\t_neuronsPerLayer = _neuronsPerLayer or math.ceil(_numInputs*.66666+_numOutputs)\n\n\t_learningRate = _learningRate or .5\n\n\t--order goes network[layer][neuron][wieght]\n\n\tlocal network = setmetatable({\n\n\t\tlearningRate = _learningRate\n\n\t},{ __index = NeuralNetwork});\n\n\tnetwork[1] = {}   --Input Layer\n\n\tfor i = 1,_numInputs do\n\n\t\tnetwork[1][i] = {}\n\n\tend\n\n\tfor i = 2,_numHiddenLayers+2 do --plus 2 represents the output layer (also need to skip input layer)\n\n\t\tnetwork[i] = {}\n\n\t\tlocal neuronsInLayer = _neuronsPerLayer\n\n\t\tif i == _numHiddenLayers+2 then\n\n\t\t\tneuronsInLayer = _numOutputs\n\n\t\tend\n\n\t\tfor j = 1,neuronsInLayer do\n\n\t\t\tnetwork[i][j] = {bias = math.random()*2-1}\n\n\t\t\tlocal numNeuronInputs = table.getn(network[i-1])\n\n\t\t\tfor k = 1,numNeuronInputs do\n\n\t\t\t\tnetwork[i][j][k] = math.random()*2-1  --return random number between -1 and 1\n\n\t\t\tend\n\n\t\tend\n\n\tend\n\n\treturn network\n\nend\n\n\n\nfunction NeuralNetwork:forewardPropagate(...)\n\tlocal arg = {...}\n\tif table.getn(arg) ~= table.getn(self[1]) and type(arg[1]) ~= \"table\" then\n\n\t\terror(\"Neural Network received \"..table.getn(arg)..\" input[s] (expected \"..table.getn(self[1])..\" input[s])\",2)\n\n\telseif type(arg[1]) == \"table\" and table.getn(arg[1]) ~= table.getn(self[1]) then\n\n\t\terror(\"Neural Network received \"..table.getn(arg[1])..\" input[s] (expected \"..table.getn(self[1])..\" input[s])\",2)\n\n\tend\n\n\tlocal outputs = {}\n\n\tfor i = 1,table.getn(self) do\n\n\t\tfor j = 1,table.getn(self[i]) do\n\n\t\t\tif i == 1 then\n\n\t\t\t\tif type(arg[1]) == \"table\" then\n\n\t\t\t\t\tself[i][j].result = arg[1][j]\n\n\t\t\t\telse\n\n\t\t\t\t\tself[i][j].result = arg[j]\n\n\t\t\t\tend\n\n\t\t\telse\n\n\t\t\t\tself[i][j].result = self[i][j].bias\n\n\t\t\t\tfor k = 1,table.getn(self[i][j]) do\n\n\t\t\t\t\tself[i][j].result = self[i][j].result + (self[i][j][k]*self[i-1][k].result)\n\n\t\t\t\tend\n\n\t\t\t\tself[i][j].result = NeuralNetwork.transfer(self[i][j].result)\n\n\t\t\t\tif i == table.getn(self) then\n\n\t\t\t\t\ttable.insert(outputs,self[i][j].result)\n\n\t\t\t\tend\n\n\t\t\tend\n\n\t\tend\n\n\n\n\tend\n\n\treturn outputs\n\nend\n\n\n\nfunction NeuralNetwork:backwardPropagate(inputs,desiredOutputs)\n\n\tif table.getn(inputs) ~= table.getn(self[1]) then\n\n\t\terror(\"Neural Network received \"..table.getn(inputs)..\" input[s] (expected \"..table.getn(self[1])..\" input[s])\",2)\n\n\telseif table.getn(desiredOutputs) ~= table.getn(self[table.getn(self)]) then\n\n\t\terror(\"Neural Network received \"..table.getn(desiredOutputs)..\" desired output[s] (expected \"..table.getn(self[table.getn(self)])..\" desired output[s])\",2)\n\n\tend\n\n\tself:forewardPropagate(inputs) --update the internal inputs and outputs\n\n\tfor i = table.getn(self),2,-1 do --iterate backwards (nothing to calculate for input layer)\n\n\t\tlocal tempResults = {}\n\n\t\tfor j = 1,table.getn(self[i]) do\n\n\t\t\tif i == table.getn(self) then --special calculations for output layer\n\n\t\t\t\tself[i][j].delta = (desiredOutputs[j] - self[i][j].result) * self[i][j].result * (1 - self[i][j].result)\n\n\t\t\telse\n\n\t\t\t\tlocal weightDelta = 0\n\n\t\t\t\tfor k = 1,table.getn(self[i+1]) do\n\n\t\t\t\t\tweightDelta = weightDelta + self[i+1][k][j]*self[i+1][k].delta\n\n\t\t\t\tend\n\n\t\t\t\tself[i][j].delta = self[i][j].result * (1 - self[i][j].result) * weightDelta\n\n\t\t\tend\n\n\t\tend\n\n\tend\n\n\tfor i = 2,table.getn(self) do\n\n\t\tfor j = 1,table.getn(self[i]) do\n\n\t\t\tself[i][j].bias = self[i][j].delta * self.learningRate\n\n\t\t\tfor k = 1,table.getn(self[i][j]) do\n\n\t\t\t\tself[i][j][k] = self[i][j][k] + self[i][j].delta * self.learningRate * self[i-1][k].result\n\n\t\t\tend\n\n\t\tend\n\n\tend\n\nend\n\n\n\nfunction NeuralNetwork:save()\n\n  --[[\n\n  File specs:\n\n    |INFO| - should be FF BP NN\n\n    |I| - number of inputs\n\n    |O| - number of outputs\n\n    |HL| - number of hidden layers\n\n    |NHL| - number of neurons per hidden layer\n\n    |LR| - learning rate\n\n    |BW| - bias and weight values\n\n  ]]--\n\n\tlocal data = \"|INFO|FF BP NN|I|\"..tostring(table.getn(self[1]))..\"|O|\"..tostring(table.getn(self[table.getn(self)]))..\"|HL|\"..tostring(table.getn(self)-2)..\"|NHL|\"..tostring(table.getn(self[2]))..\"|LR|\"..tostring(self.learningRate)..\"|BW|\"\n\n\tfor i = 2,table.getn(self) do -- nothing to save for input layer\n\n\t\tfor j = 1,table.getn(self[i]) do\n\n\t\t\tlocal neuronData = tostring(self[i][j].bias)..\"{\"\n\n\t\t\tfor k = 1,table.getn(self[i][j]) do\n\n\t\t\t\tneuronData = neuronData..tostring(self[i][j][k])\n\n\t\t\t\tneuronData = neuronData..\",\"\n\n\t\t\tend\n\n\t\t\tdata = data..neuronData..\"}\"\n\n\t\tend\n\n\tend\n\n\tdata = data..\"|END|\"\n\n\treturn data\n\nend\n\nfunction NeuralNetwork.load( data)\n\n\tlocal dataPos = string.find(data,\"|\")+1\n\n\tlocal currentChunk = string.sub( data, dataPos, string.find(data,\"|\",dataPos)-1)\n\n\tlocal dataPos = string.find(data,\"|\",dataPos)+1\n\n\tlocal _inputs, _outputs, _hiddenLayers, _neuronsPerLayer, _learningRate\n\n\tlocal biasWeights = {}\n\n\tlocal errorExit = false\n\n\twhile currentChunk ~= \"END\" and not errorExit do\n\n\t\tif currentChunk == \"INFO\" then\n\n\t\t\tcurrentChunk = string.sub( data, dataPos, string.find(data,\"|\",dataPos)-1)\n\n\t\t\tdataPos = string.find(data,\"|\",dataPos)+1\n\n\t\t\tif currentChunk ~= \"FF BP NN\" then\n\n\t\t\t\terrorExit = true\n\n\t\t\tend\n\n\t\telseif currentChunk == \"I\" then\n\n\t\t\tcurrentChunk = string.sub( data, dataPos, string.find(data,\"|\",dataPos)-1)\n\n\t\t\tdataPos = string.find(data,\"|\",dataPos)+1\n\n\t\t\t_inputs = tonumber(currentChunk)\n\n\t\telseif currentChunk == \"O\" then\n\n\t\t\tcurrentChunk = string.sub( data, dataPos, string.find(data,\"|\",dataPos)-1)\n\n\t\t\tdataPos = string.find(data,\"|\",dataPos)+1\n\n\t\t\t_outputs = tonumber(currentChunk)\n\n\t\telseif currentChunk == \"HL\" then\n\n\t\t\tcurrentChunk = string.sub( data, dataPos, string.find(data,\"|\",dataPos)-1)\n\n\t\t\tdataPos = string.find(data,\"|\",dataPos)+1\n\n\t\t\t_hiddenLayers = tonumber(currentChunk)\n\n\t\telseif currentChunk == \"NHL\" then\n\n\t\t\tcurrentChunk = string.sub( data, dataPos, string.find(data,\"|\",dataPos)-1)\n\n\t\t\tdataPos = string.find(data,\"|\",dataPos)+1\n\n\t\t\t_neuronsPerLayer = tonumber(currentChunk)\n\n\t\telseif currentChunk == \"LR\" then\n\n\t\t\tcurrentChunk = string.sub( data, dataPos, string.find(data,\"|\",dataPos)-1)\n\n\t\t\tdataPos = string.find(data,\"|\",dataPos)+1\n\n\t\t\t_learningRate = tonumber(currentChunk)\n\n\t\telseif currentChunk == \"BW\" then\n\n\t\t\tcurrentChunk = string.sub( data, dataPos, string.find(data,\"|\",dataPos)-1)\n\n\t\t\tdataPos = string.find(data,\"|\",dataPos)+1\n\n\t\t\tlocal subPos = 1\n\n\t\t\tlocal subChunk\n\n\t\t\tfor i = 1,_hiddenLayers+1 do\n\n\t\t\t\tbiasWeights[i] = {}\n\n\t\t\t\tlocal neuronsInLayer = _neuronsPerLayer\n\n\t\t\t\tif i == _hiddenLayers+1 then\n\n\t\t\t\t\tneuronsInLayer = _outputs\n\n\t\t\t\tend\n\n\t\t\t\tfor j = 1,neuronsInLayer do\n\n\t\t\t\t\tbiasWeights[i][j] = {}\n\n\t\t\t\t\tbiasWeights[i][j].bias = tonumber(string.sub(currentChunk,subPos,string.find(currentChunk,\"{\",subPos)-1))\n\n\t\t\t\t\tsubPos = string.find(currentChunk,\"{\",subPos)+1\n\n\t\t\t\t\tsubChunk = string.sub( currentChunk, subPos, string.find(currentChunk,\",\",subPos)-1)\n\n\t\t\t\t\tlocal maxPos = string.find(currentChunk,\"}\",subPos)\n\n\t\t\t\t\twhile subPos < maxPos do\n\n\t\t\t\t\t\ttable.insert(biasWeights[i][j],tonumber(subChunk))\n\n\t\t\t\t\t\tsubPos = string.find(currentChunk,\",\",subPos)+1\n\n\t\t\t\t\t\tif string.find(currentChunk,\",\",subPos) ~= nil then\n\n\t\t\t\t\t\t\tsubChunk = string.sub( currentChunk, subPos, string.find(currentChunk,\",\",subPos)-1)\n\n\t\t\t\t\t\tend\n\n\t\t\t\t\tend\n\n\t\t\t\t\tsubPos = maxPos+1\n\n\t\t\t\tend\n\n\t\t\tend\n\n\t\tend\n\n\t\tcurrentChunk = string.sub( data, dataPos, string.find(data,\"|\",dataPos)-1)\n\n\t\tdataPos = string.find(data,\"|\",dataPos)+1\n\n\tend\n\n\tif errorExit then\n\n\t\terror(\"Failed to load Neural Network:\"..currentChunk,2)\n\n\tend\n\n\tlocal network = setmetatable({\n\n\t\tlearningRate = _learningRate\n\n\t},{ __index = NeuralNetwork});\n\n\tnetwork[1] = {}   --Input Layer\n\n\tfor i = 1,_inputs do\n\n\t\tnetwork[1][i] = {}\n\n\tend\n\n\tfor i = 2,_hiddenLayers+2 do --plus 2 represents the output layer (also need to skip input layer)\n\n\t\tnetwork[i] = {}\n\n\t\tlocal neuronsInLayer = _neuronsPerLayer\n\n\t\tif i == _hiddenLayers+2 then\n\n\t\t\tneuronsInLayer = _outputs\n\n\t\tend\n\n\t\tfor j = 1,neuronsInLayer do\n\n\t\t\tnetwork[i][j] = {bias = biasWeights[i-1][j].bias}\n\n\t\t\tlocal numNeuronInputs = table.getn(network[i-1])\n\n\t\t\tfor k = 1,numNeuronInputs do\n\n\t\t\t\tnetwork[i][j][k] = biasWeights[i-1][j][k]\n\n\t\t\tend\n\n\t\tend\n\n\tend\n\n\treturn network\n\nend\n\nlocal Sign = GetPartFromPort(2, \"Sign\")\nlocal Sign2 = GetPartFromPort(3, \"Sign\")\nlocal Keyboard = GetPartFromPort(1, \"Keyboard\")\nlocal Microphone = GetPartFromPort(4, \"Microphone\")\nlocal Network = NeuralNetwork.create(10, 10, 4, 4, 0.1)\n\nfunction TextToChar(TextStuff)\n\tlocal List = {}\n\tfor i=1, #TextStuff do\n\t\ttable.insert(List,string.byte(TextStuff, i))\n\tend\n\treturn List\nend\nlocal Dictionary = {\n\t\"Hi\",\n\t\"Hello\",\n\t\"Sup\",\n\t\"How\",\n\t\"Though\",\n\t\"Pretty\",\n\t\"Cool\",\n\t\"Nice\",\n\t\"You\",\n\t\"Me\",\n\t\"That\",\n\t\"Guy\",\n\t\"Amazing\",\n\t\"What\",\n\t\"Are\",\n\t\"Doing\",\n\t\"Slick\",\n\t\"There\",\n\t\"And\",\n\t\"Dont\",\n\t\"Now\",\n\t\"Math\",\n\t\"Do\",\n\t\"Does\",\n\t\"That\",\n\t\"Go\",\n\t\"Please\",\n\t\"Say\",\n\t\"Something\",\n\t\"Got\",\n\t\"Like\",\n\t\"Machine\",\n\t\"Hey\",\n\t\"Of\",\n\t\"The\",\n\t\"I\",\n\t\"A\"\n}\nlocal function Epoch(Text, Gens, OGNetworkSave)\n\tlocal CurrentAwnser = nil\n\tlocal CurrentNetwork = nil\n\tlocal CurrentPoints = -1\n\tif Text == \"\" then\n\t\tText = Dictionary[math.random(1, #Dictionary)]\n\tend\n\tfor i=1, Gens do\n\t\tlocal Points = 0\n\t\tlocal Network = NeuralNetwork.create(#Text-1, 10, 2, 4, 0.1)\n\t\tif OGNetworkSave ~= nil then\n\t\t\tNetwork.load(OGNetworkSave)\n\t\tend\n\t\tlocal Table = {}\n\t\tlocal Train = {}\n\t\tlocal Train2 = {}\n\t\tlocal Train3 = {}\n\t\tlocal Train4 = {}\n\t\tlocal RandomDictionary = Dictionary[math.random(1, #Dictionary)]\n\t\tfor i=1, #Text-1 do\n\t\t\ttable.insert(Table, string.byte(Text, i))\n\t\t\ttable.insert(Train3, math.random(-100, 100))\n\t\t\ttable.insert(Train, math.random(-100, 100))\n\t\tend\n\t\tfor r=1, 10 do\n\t\t\ttable.insert(Train2, math.random(-10000, 10000)/10000)\n\t\tend\n\t\tfor e=1, 10 do\n\t\t\tNetwork:backwardPropagate(Train3, Train2)\n\t\tend\n\t\tlocal Propagate = Network:forewardPropagate(table.unpack(Table))\n\t\tlocal Awnser = \"\"\n\t\tfor i=1, #Propagate do\n\t\t\tPropagate[i]*=100\n\t\t\tPropagate[i] = math.floor(Propagate[i])\n\t\t\tPropagate[i] = string.char(Propagate[i])\n\t\t\tAwnser = Awnser..Propagate[i]\n\t\tend\n\t\tfor Letter=1, #Dictionary do\n\t\t\tif string.find(string.lower(Awnser), string.lower(Dictionary[Letter])) then\n\t\t\t\tPoints += 1\n\t\t\tend\n\t\tend\n\t\tif Points > CurrentPoints then\n\t\t\tCurrentPoints = Points\n\t\t\tCurrentNetwork = Network\n\t\t\tCurrentAwnser = Awnser\n\t\tend\n\tend\n\treturn CurrentNetwork, CurrentAwnser, CurrentPoints\nend\nlocal function Epoch2(Text, Gens, OGNetworkSave)\n\tlocal CurrentAwnser = nil\n\tlocal CurrentNetwork = nil\n\tlocal CurrentPoints = -1\n\tif Text == \"\" then\n\t\tText = Dictionary[math.random(1, #Dictionary)]\n\tend\n\tfor i=1, Gens do\n\t\tlocal Points = 0\n\t\tlocal Table = {}\n\t\tlocal Train = {}\n\t\tlocal Train2 = {}\n\t\tlocal Train3 = {}\n\t\tlocal Train4 = {}\n\t\tlocal RandomDictionary = Dictionary[math.random(1, #Dictionary)]\n\t\tlocal RandomDictionaryNum = {}\n\t\tfor i=1, #Text-1 do\n\t\t\ttable.insert(Table, string.byte(Text, i))\n\t\t\ttable.insert(Train3, math.random(-100, 100))\n\t\t\ttable.insert(Train, math.random(-100, 100))\n\t\tend\n\t\tfor r=1, 10 do\n\t\t\ttable.insert(Train2, math.random(-10000, 10000)/10000)\n\t\tend\n\t\tfor Length=1, #RandomDictionary do\n\t\t\ttable.insert(RandomDictionaryNum, string.byte(RandomDictionary, Length))\n\t\tend\n\t\tlocal Network = NeuralNetwork.create(#RandomDictionary, #Table, 2, 4, 0.1)\n\t\tif OGNetworkSave ~= nil then\n\t\t\tNetwork.load(OGNetworkSave)\n\t\tend\n\t\tfor e=1, 10 do\n\t\t\tNetwork:backwardPropagate(RandomDictionaryNum, Table)\n\t\tend\n\t\tlocal Test = Network.save()\n\t\tlocal Network = NeuralNetwork.create(#Table, 10, 2, 4, 0.1)\n\t\tNetwork.load(Test)\n\t\tlocal Propagate = Network:forewardPropagate(table.unpack(Table))\n\t\tlocal Awnser = \"\"\n\t\tfor i=1, #Propagate do\n\t\t\tPropagate[i]*=100\n\t\t\tPropagate[i] = math.floor(Propagate[i])\n\t\t\tPropagate[i] = string.char(Propagate[i])\n\t\t\tAwnser = Awnser..Propagate[i]\n\t\tend\n\t\tfor Letter=1, #Dictionary do\n\t\t\tif string.find(string.lower(Awnser), string.lower(Dictionary[Letter])) then\n\t\t\t\tPoints += 1\n\t\t\tend\n\t\tend\n\t\tif Points > CurrentPoints then\n\t\t\tCurrentPoints = Points\n\t\t\tCurrentNetwork = Network\n\t\t\tCurrentAwnser = Awnser\n\t\tend\n\tend\n\treturn CurrentNetwork, CurrentAwnser, CurrentPoints\nend\nlocal Train = false\nlocal LasteSave = nil\nlocal function Test(Text)\n\tlocal Network = NeuralNetwork.create(#Text-1, 10, 2, 4, 0.01)\n\tif LasteSave ~= nil then\n\t\tNetwork.load(LasteSave)\n\tend\n\tlocal Testing = TextToChar(\"Hi\")\n\tlocal Testing2 = TextToChar(\"hi\")\n\tprint(string.len(Text)-1)\n\tlocal e = {72, 105}\n\tlocal Table = {}\n\tfor i=1, #Text-1 do\n\t\ttable.insert(Table, string.byte(Text, i))\n\tend\n\tprint(\"Test\")\n\tlocal Propagate = Network:forewardPropagate(table.unpack(Table))\n\tprint(#Propagate)\n\tlocal Awnser = \"\"\n\tfor i=1, #Propagate do\n\t\tPropagate[i]*=100\n\t\tPropagate[i] = math.floor(Propagate[i])\n\t\tPropagate[i] = string.char(Propagate[i])\n\t\tAwnser = Awnser..Propagate[i]\n\tend\n\tSign:Configure({SignText=Awnser})\n\tLasteSave = Network.save()\nend\nlocal function Test2(Text)\n\tlocal Network, Awnser, Points = Epoch2(Text, 10, LasteSave)\n\tSign:Configure({SignText=Awnser})\n\tSign2:Configure({SignText=Points})\n\tLasteSave = Network.save()\nend\nlocal function Test3(Player, Text)\n\tlocal Network, Awnser, Points = Epoch2(Text, 10, LasteSave)\n\tSign:Configure({SignText=Awnser})\n\tSign2:Configure({SignText=Points})\n\tLasteSave = Network.save()\n\tBeep(1)\nend\nKeyboard:Connect(\"TextInputted\", Test2)\nMicrophone:Connect(\"Chatted\", Test3)"}],["AAAAAICl1r8AAAAAAAA7wAAAAADITvw/AAAAAAAA8D8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAAAEAAAAAAAADwPwAAAAAAAPA//wC/ZmZm","Polysilicon",{"PolysiliconMode":"2","Frequency":"1","SDATA":"0"}],["AAAAAFArAUAAAAAAAAA7wAAAAADAic2/AAAAAAAA8D8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAA8D8AAAAAAADwPwAAAAAAAPA/Y19iZmZm","Port",{"PortID":"2"}],["AAAAAICl1r8AAAAAAIA6wAAAAAA4sfu/AAAAAAAA8D8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAQAAAAAAAAABAZGRkZmZm","PowerCell"],["AAAAAGCp/b8AAAAAAAA7wAAAAADAic2/AAAAAAAA8D8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAA8D8AAAAAAADwPwAAAAAAAPA/Y19iZmZm","Port",{"PortID":"1"}],["AAAAAAC1wj8AAAAAAAA6wAAAAABO7BDAAAAAAAAA8L8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPC/AAAAAAAACEAAAAAAAAAIQAAAAAAAAAhA7erqZmZm","RTG"],["AAAAAICl1r8AAAAAAAA7wAAAAABkJwpAAAAAAAAA8L8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAAAEAAAAAAAADwPwAAAAAAAABA2oVBZmZm","Button",{"TriggerMode":"0","KeyInput":""}],["AAAAAKiVEkAAAAAAAIA6wAAAAADAic2/AAAAAAAA8L8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAAEEAAAAAAAAAAQAAAAAAAAPA/W11pZmZm","Sign",{"TextFont":"Enum.Font.SciFi","TextColor":"1, 1, 1","SignText":"Text"}],["AAAAAICl1r8AAAAAAAA5wAAAAACQneg/AAAAAAAA8L8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwPwAAAAAAAAAAAAAAAAAAEEAAAAAAAAAAQAAAAAAAAPA/W11pZmZm","Sign",{"TextFont":"Enum.Font.SciFi","TextColor":"1, 1, 1","SignText":"Text"}]]
